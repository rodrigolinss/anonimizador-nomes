{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, AutoConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Carregar modelo e tokenizer\n",
    "nome_modelo = \"lfcc/bert-portuguese-ner\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(nome_modelo)\n",
    "modelo = AutoModelForTokenClassification.from_pretrained(nome_modelo)\n",
    "\n",
    "# Função para anonimizar nomes no texto\n",
    "def anonimizar_nome(texto):\n",
    "    tamanho_pedido = 512\n",
    "\n",
    "    # Tokenizar o texto e obter os offsets dos tokens\n",
    "    entradas = tokenizer(\n",
    "        texto,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=tamanho_pedido,\n",
    "        return_offsets_mapping=True,  # Obter offsets dos tokens para processamento posterior\n",
    "    )\n",
    "    mapeamento_offset = entradas.pop(\"offset_mapping\")[0]  # Remover do dicionário e armazenar separadamente\n",
    "\n",
    "    # Executar o modelo para obter as previsões\n",
    "    saídas = modelo(**entradas)\n",
    "    logits = saídas.logits\n",
    "\n",
    "    # Carregar a configuração do modelo para obter o mapeamento das labels\n",
    "    configuracao = AutoConfig.from_pretrained(nome_modelo)\n",
    "    mapeamento_labels = configuracao.id2label\n",
    "\n",
    "    # Obter as previsões\n",
    "    indices_classes_previstas = torch.argmax(logits, dim=-1)[0]\n",
    "    labels_previstas = [mapeamento_labels[idx.item()] for idx in indices_classes_previstas]\n",
    "\n",
    "    # Anonimizar o texto\n",
    "    texto_anonimizado = list(texto)  # Converter para lista para substituição mutável\n",
    "\n",
    "    for (inicio, fim), label in zip(mapeamento_offset, labels_previstas):\n",
    "        if \"Pessoa\" in label:  # Verificar se o label está relacionado a uma pessoa\n",
    "            for i in range(inicio, fim):  # Substituir o intervalo de caracteres no texto original\n",
    "                texto_anonimizado[i] = \"*\"\n",
    "\n",
    "    # Juntar a lista modificada de volta em uma string\n",
    "    texto_anonimizado = \"\".join(texto_anonimizado)\n",
    "    \n",
    "    return texto_anonimizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Função para anonimizar dados de arquivos Excel ou CSV\n",
    "def anonimizar_arquivo(input_caminho, arquivo_saida, colunas_anonimizar):\n",
    "    # Determinar o formato do arquivo pela extensão\n",
    "    extensao_arquivo = os.path.splitext(input_caminho)[1].lower()\n",
    "    \n",
    "    # Ler o arquivo conforme seu formato\n",
    "    if extensao_arquivo in ['.xlsx', '.xls']:\n",
    "        df = pd.read_excel(input_caminho)  # Arquivo Excel\n",
    "    elif extensao_arquivo == '.csv':\n",
    "        df = pd.read_csv(input_caminho)  # Arquivo CSV\n",
    "    else:\n",
    "        raise ValueError(\"Formato de arquivo não suportado. Por favor, forneça um arquivo Excel (.xlsx, .xls) ou CSV (.csv).\")\n",
    "\n",
    "    # Garantir que 'colunas_anonimizar' seja uma lista, mesmo que seja uma string única\n",
    "    if isinstance(colunas_anonimizar, str):\n",
    "        colunas_anonimizar = [colunas_anonimizar]\n",
    "\n",
    "    # Processar apenas as colunas que existem no DataFrame\n",
    "    colunas_existentes = [col for col in colunas_anonimizar if col in df.columns]\n",
    "\n",
    "    if not colunas_existentes:\n",
    "        raise ValueError(f\"Nenhuma das colunas especificadas existe no arquivo. Colunas disponíveis: {list(df.columns)}\")\n",
    "\n",
    "    # Remover linhas onde as colunas a serem anonimizadas estão vazias\n",
    "    df = df.dropna(subset=colunas_existentes)\n",
    "\n",
    "    for coluna in colunas_existentes:\n",
    "        df[coluna] = df[coluna].apply(anonimizar_nome)  # Aplicar a anonimização nas colunas\n",
    "    \n",
    "    # Salvar o DataFrame atualizado no formato especificado\n",
    "    extensao_saida = os.path.splitext(arquivo_saida)[1].lower()\n",
    "\n",
    "    if extensao_saida in ['.xlsx', '.xls']:\n",
    "        df.to_excel(arquivo_saida, index=False)\n",
    "        print(f'Arquivo salvo como {arquivo_saida}')\n",
    "    elif extensao_saida == '.csv':\n",
    "        df.to_csv(arquivo_saida, index=False)\n",
    "        print(f'Arquivo salvo como {arquivo_saida}')\n",
    "    else:\n",
    "        raise ValueError(\"Formato de arquivo de saída não suportado. Por favor, forneça um arquivo Excel (.xlsx, .xls) ou CSV (.csv).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Informe o caminho do arquivo original, o nome do arquivo de saída e a(s) coluna(s) a serem processadas\n",
    "anonimizar_arquivo('arquivo.xlsx', 'arquivo_anonimizado.xlsx', 'TEXTO_LIVRE')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
